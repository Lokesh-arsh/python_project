{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a376242",
   "metadata": {},
   "source": [
    "🧠 AI Job Market Analysis — Data Cleaning\n",
    "\n",
    "This notebook focuses on preparing and cleaning the AI job market dataset to ensure accurate, reliable analysis.\n",
    "\n",
    "**Objectives:**\n",
    "- Handle missing and inconsistent data  \n",
    "- Standardize column names and formats  \n",
    "- Remove duplicates and irrelevant records  \n",
    "- Prepare a clean dataset for visualization\n",
    "\n",
    "**Tools Used:** Python, Pandas, NumPy  \n",
    "**Dataset:** AI Job Market Dataset (Kaggle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481779af",
   "metadata": {},
   "source": [
    "### 📦 Importing Required Libraries\n",
    "We import Python libraries used for data manipulation and cleaning.  \n",
    "`Pandas` handles structured data, and `NumPy` helps with numerical operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8efae0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path=\"C:\\\\Users\\\\akash\\\\Downloads\\\\AI_jobs\\\\ai_job_market.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255285f",
   "metadata": {},
   "source": [
    "### 📂 Loading the Dataset\n",
    "We load the raw AI job dataset into a DataFrame for cleaning and exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac728890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   job_id            2000 non-null   int64 \n",
      " 1   company_name      2000 non-null   object\n",
      " 2   industry          2000 non-null   object\n",
      " 3   job_title         2000 non-null   object\n",
      " 4   skills_required   2000 non-null   object\n",
      " 5   experience_level  2000 non-null   object\n",
      " 6   employment_type   2000 non-null   object\n",
      " 7   location          2000 non-null   object\n",
      " 8   salary_range_usd  2000 non-null   object\n",
      " 9   posted_date       2000 non-null   object\n",
      " 10  company_size      2000 non-null   object\n",
      " 11  tools_preferred   2000 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 187.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bbaf956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>job_title</th>\n",
       "      <th>skills_required</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>location</th>\n",
       "      <th>salary_range_usd</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>company_size</th>\n",
       "      <th>tools_preferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Foster and Sons</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NumPy, Reinforcement Learning, PyTorch, Scikit...</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Tracybury, AR</td>\n",
       "      <td>92860-109598</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Large</td>\n",
       "      <td>KDB+, LangChain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boyd, Myers and Ramirez</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Computer Vision Engineer</td>\n",
       "      <td>Scikit-learn, CUDA, SQL, Pandas</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Lake Scott, CU</td>\n",
       "      <td>78523-144875</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>Large</td>\n",
       "      <td>FastAPI, KDB+, TensorFlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>King Inc</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Quant Researcher</td>\n",
       "      <td>MLflow, FastAPI, Azure, PyTorch, SQL, GCP</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>East Paige, CM</td>\n",
       "      <td>124496-217204</td>\n",
       "      <td>2025-09-18</td>\n",
       "      <td>Large</td>\n",
       "      <td>BigQuery, PyTorch, Scikit-learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cooper, Archer and Lynch</td>\n",
       "      <td>Tech</td>\n",
       "      <td>AI Product Manager</td>\n",
       "      <td>Scikit-learn, C++, Pandas, LangChain, AWS, R</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Perezview, FI</td>\n",
       "      <td>50908-123743</td>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>Large</td>\n",
       "      <td>TensorFlow, BigQuery, MLflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hall LLC</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Excel, Keras, SQL, Hugging Face</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Contract</td>\n",
       "      <td>North Desireeland, NE</td>\n",
       "      <td>98694-135413</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Large</td>\n",
       "      <td>PyTorch, LangChain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id              company_name    industry                 job_title  \\\n",
       "0       1           Foster and Sons  Healthcare              Data Analyst   \n",
       "1       2   Boyd, Myers and Ramirez        Tech  Computer Vision Engineer   \n",
       "2       3                  King Inc        Tech          Quant Researcher   \n",
       "3       4  Cooper, Archer and Lynch        Tech        AI Product Manager   \n",
       "4       5                  Hall LLC     Finance            Data Scientist   \n",
       "\n",
       "                                     skills_required experience_level  \\\n",
       "0  NumPy, Reinforcement Learning, PyTorch, Scikit...              Mid   \n",
       "1                    Scikit-learn, CUDA, SQL, Pandas           Senior   \n",
       "2          MLflow, FastAPI, Azure, PyTorch, SQL, GCP            Entry   \n",
       "3       Scikit-learn, C++, Pandas, LangChain, AWS, R              Mid   \n",
       "4                    Excel, Keras, SQL, Hugging Face           Senior   \n",
       "\n",
       "  employment_type               location salary_range_usd posted_date  \\\n",
       "0       Full-time          Tracybury, AR     92860-109598  2025-08-20   \n",
       "1       Full-time         Lake Scott, CU     78523-144875  2024-03-22   \n",
       "2       Full-time         East Paige, CM    124496-217204  2025-09-18   \n",
       "3       Full-time          Perezview, FI     50908-123743  2024-05-08   \n",
       "4        Contract  North Desireeland, NE     98694-135413  2025-02-24   \n",
       "\n",
       "  company_size                  tools_preferred  \n",
       "0        Large                  KDB+, LangChain  \n",
       "1        Large        FastAPI, KDB+, TensorFlow  \n",
       "2        Large  BigQuery, PyTorch, Scikit-learn  \n",
       "3        Large     TensorFlow, BigQuery, MLflow  \n",
       "4        Large               PyTorch, LangChain  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the dataset to get a quick look at its structure and contents\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f258ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (2000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Display the number of rows and columns in the dataset\n",
    "print(\"Shape of the dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a1b0207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns:\n",
      " Index(['job_id', 'company_name', 'industry', 'job_title', 'skills_required',\n",
      "       'experience_level', 'employment_type', 'location', 'salary_range_usd',\n",
      "       'posted_date', 'company_size', 'tools_preferred'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display all column names in the dataset\n",
    "print(\"\\nColumns:\\n\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aede9ce",
   "metadata": {},
   "source": [
    "### 🔍 Checking for Missing Values\n",
    "We identify columns with missing data to decide how to handle them later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eeb2d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      " job_id              0\n",
      "company_name        0\n",
      "industry            0\n",
      "job_title           0\n",
      "skills_required     0\n",
      "experience_level    0\n",
      "employment_type     0\n",
      "location            0\n",
      "salary_range_usd    0\n",
      "posted_date         0\n",
      "company_size        0\n",
      "tools_preferred     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff4e61a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Job Titles: 8\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique job titles in the dataset\n",
    "print(\"\\nUnique Job Titles:\", df['job_title'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7928e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Companies: 1909\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique company name in the dataset\n",
    "print(\"\\nUnique Companies:\", df['company_name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52606da",
   "metadata": {},
   "source": [
    "### 🧹 Cleaning Date and Skill Columns\n",
    "We perform two key cleaning steps:\n",
    "1. Convert the `posted_date` column to datetime format for time-based analysis.  \n",
    "2. Split the `skills_required` column into a list of individual skills (removing extra spaces).  \n",
    "\n",
    "Finally, we check the dataset’s structure using `df.info()` to verify changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc426792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   job_id            2000 non-null   int64         \n",
      " 1   company_name      2000 non-null   object        \n",
      " 2   industry          2000 non-null   object        \n",
      " 3   job_title         2000 non-null   object        \n",
      " 4   skills_required   2000 non-null   object        \n",
      " 5   experience_level  2000 non-null   object        \n",
      " 6   employment_type   2000 non-null   object        \n",
      " 7   location          2000 non-null   object        \n",
      " 8   salary_range_usd  2000 non-null   object        \n",
      " 9   posted_date       2000 non-null   datetime64[ns]\n",
      " 10  company_size      2000 non-null   object        \n",
      " 11  tools_preferred   2000 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(10)\n",
      "memory usage: 187.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df['posted_date']= pd.to_datetime(df['posted_date'])\n",
    "df['skills_required'] = df['skills_required'].apply(\n",
    "    lambda x: [skill.strip() for skill in x.split(',')] if pd.notna(x) else []\n",
    ")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a950c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'salary_range_usd' column into 'min_salary' and 'max_salary'\n",
    "df[[\"min_salary\", \"max_salary\"]] = df[\"salary_range_usd\"].str.split(\"-\", expand=True)\n",
    "\n",
    "# Convert the split string values into numeric types (integers/floats)\n",
    "# This ensures we can perform mathematical operations on salary data\n",
    "df[\"min_salary\"]=pd.to_numeric(df[\"min_salary\"])\n",
    "df[\"max_salary\"]=pd.to_numeric(df[\"max_salary\"])\n",
    "\n",
    "# Correct calculation: (min + max) / 2\n",
    "df[\"avg_salary\"] = (df[\"min_salary\"] + df[\"max_salary\"]) / 2\n",
    "df['avg_salary'] = pd.to_numeric(df['avg_salary'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bf71147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name\n",
       "Johnson LLC        4\n",
       "Smith Inc          3\n",
       "Taylor PLC         3\n",
       "Anderson PLC       3\n",
       "Martin and Sons    3\n",
       "Lee Group          3\n",
       "Sanchez Ltd        3\n",
       "Williams Ltd       3\n",
       "Johnson Inc        3\n",
       "Jones and Sons     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of job postings per company and select the top 10\n",
    "job_count=df[\"company_name\"].value_counts().head(10)\n",
    "job_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e58812c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Convert the column to datetime\n",
    "df['posted_date'] = pd.to_datetime(df['posted_date'], errors='coerce')\n",
    "\n",
    "# 2️⃣ Extract year and month into new columns\n",
    "df['year'] = df['posted_date'].dt.year\n",
    "df['month'] = df['posted_date'].dt.month_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6327dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0caf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
